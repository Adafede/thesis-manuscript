## Data & Computational Era {#sec:computational}

The classical reductionist approach detailed above, allowing, from a complex organism, to scrutinize the smallest quantitative change of a single metabolite is impressive, both by its precision and by the technologies used.
Along the way, large amounts of data are generated, capturing much more than these important, but very targeted changes.
And it is precisely this data that can extend the meticulous analysis to a broader context.

This extension has already been illustrated by Joël de Rosnay in his book, *Le Macroscope - Vers une vision globale* [@isbn:2-02-002818-2].
This book advocates a *systemic* approach to complement the classical analytical approach.
Influenced by *cybernetics*, or how a system senses and reacts to a stimulus, the book describes three main instruments that should be used in Science:
The first instrument is the *microscope*, allowing one to study the *infinitely small*, which in the field of phytochemistry could correspond to the various detectors listed before.
The second one is the *telescope*, allowing one to study the *infinitely large*.
This instrument is mainly used in physics and not really in biology or chemistry, unlike the last instrument, the *macroscope*.
The *macroscope* is a symbolical instrument allowing one to study the *infinitely complex*.
This symbolic instrument is very similar to modern computers.

To that extent, computers now allow the study of the *relatively complex*, and adequate tools and resources must be developed to achieve a broader picture of what is captured by targeted experiments [@doi:10.1126/science.1142502].

### The «-omics»

This broader picture is also the goal of the different "-omics" fields.
Their holistic approach focuses on complex interactions within or between biological systems [@doi:10.1042/EBC20180003].
They are now used across biology-related fields, before or in complement to targeted analysis.
The central dogma of molecular biology is that [DNA](#dna) makes [RNA](#rna) and [RNA](#rna) makes proteins [@doi:10.1371/journal.pbio.2003243].
The complexity of processes involved is slightly higher than that, and therefore, many proposals have been made to remodel it.
Among them, a proposal was made to place *metabolomics* at the center of other "-omics", in a multiinteraction dynamic perspective [@doi:10.1007/s11306-021-01800-8].
The object of study of metabolomics is the *metabolome*, the same way as genomics studies the *genome*, transcriptomics the *transcriptome*, and proteomics the *proteome*.
While the *genome*, *transcriptome*, and *proteome* are relatively restricted in terms of diversity, it is not the case with the *metabolome*.
This is due to the number of available building blocks of each *-ome*.

A *genome* is the complete set of genetic information in an organism [@url:https://www.nature.com/scitable/definition/genome-43]. 
This information is encoded in [DNA](#dna) as a sequence of four nucleotides.
These nucleotides are adenine (A), guanine (G), cytosine (C), and thymine (T) [@doi:10.1201/9781315735368].
Small sections of [DNA](#dna), called genes, code for [RNA](#rna) and proteins.

The full range of [RNA](#rna) expressed by a *genome* is known as its *transcriptome* [@url:https://www.nature.com/scitable/definition/transcriptome-296].
In the case of [RNA](#rna), uracil (U) replaces thymine (T) in the sequence of nucleotides [@doi:10.1201/9781315735368].

A *proteome* is the complete set of proteins expressed by an organism [@url:https://www.nature.com/scitable/definition/proteome-297].
These proteins are made of 22 building blocks [@doi:10.1038/nchembio847], called amino acids, of which 21 are found in eukaryotes.

Therefore, studying the *metabolome*, or "all small molecule (<1500 Da) metabolites found in a specific cell, organ or organism" [@doi:10.1093/nar/gkl923], appears more challenging, as they are not restricted by such building blocks.
Moreover, the turnover rate of metabolites is over two magnitudes higher than the ones of genes and proteins and lies in the range of seconds [@doi:10.1021/ac8016899].
Taking all these considerations into account, metabolomics, its holistic approach and its close link with bioinformatics will be described below.

#### Metabolomics

In the same way that it studies its objects of analysis, metabolomics encompasses a whole series of different tools, from data acquisition to its treatment, statistical processing and biological interpretation [@doi:10/ch97dw; @doi:10.1016/j.jare.2014.10.003].
While metabolomics approaches are not limited to [MS](#ms) [@doi:10/dgtr9s], the most of them are performed with [MS](#ms).
This is due to the good compromise [MS](#ms) offers in terms of sensitivity, speed [@doi:10.1016/j.copbio.2014.08.006] and selectivity [@doi:10.1074/jbc.R111.238691; @doi:10.1002/cbic.200500151]. 
As [MS](#ms) detectors and modes of acquisition were detailed before, current section will focus on the data generated by [MS](#ms)-based metabolomics and the tools and resources required to extract biological knowledge out of them. 

##### Data Conversion (From Proprietary to Open)

The first step after data acquisition is generally to convert the obtained file to an open format.
This step is crucial, because it allows then to exchange data between laboratories, and to process them with any software, open or not.
The currently most used software in this respect is MSConvert [@doi:10.1038/nbt.2377].
Years after its development, other solutions to convert the data have been developed, but with a more focused audience, either because of the language they use [@doi:10.1021/acs.jproteome.0c00866], or their ability to convert the data of limited instruments only [@doi:10.1021/acs.jproteome.9b00328].

##### Data Processing (From Complex Chromatogram(s) to Features)

After conversion, the next major step is to process the obtained data.
Starting from a *chromatogram*, this step will produce a *feature list*, with associated *spectra* and metadata [@doi:10.1093/gigascience/gix037].
The main relevant terms of this step are illustrated in Figure @fig:intro-feature.

![**Common terminology used in metabolomics**. The notions of *chromatogram*, *spectrum*, *peak*, *feature*, and *feature list (or table)* are illustrated.](images/intro-feature.pdf "intro-feature"){#fig:intro-feature short-caption="Common Terminology Used in metabolomics" align="center" width="100%"}

The initial object in Figure @fig:intro-feature is a *chromatogram*.
It corresponds to a series of intensities as a function of the retention time ([RT](#rt)).
In the case of [MS](#ms), this chromatogram hides a third dimension, the mass-to-charge ratio, or [*m/z*](#m/z) ([PDA](#pda) also holds a third dimension, the wavelength).
This third dimension is used to define a *spectrum*.

A spectrum is a series of intensities as a function of the [*m/z*](#mz), at a given time point.
This spectrum can eventually be combined with other spectra to lead to a *pseudospectrum*.
In the case of [MS](#ms) and [MS/MS](#msms) acquisition, different spectra co-exist on a same chromatogram (*full scan* and *tandem* spectra).

The first processing step is therefore, from the initial data, to re-construct several chromatograms, one for each [*m/z*](#mz) (with a given tolerance).
From these re-constructed chromatograms, different algorithmic tools exist to extract *peaks* from a chromatogram [@doi:10.1021/ac051437y; @doi:10.1021/ac202450g; @doi:10.1021/acs.analchem.9b01424].
Depending on their complexity, the algorithms can consider two or three dimensions to extract the peaks.
This step is generally called *deconvolution*.

A peak consists of a series of descriptive parameters related to an [*m/z*](#m/z) and an [RT](#rt).
Classically, most common parameters describe the peak intensity, its area, its minimal and maximal [RT](#rt)s and [*m/z*](#m/z)s, the [RT](#rt) of its apex (global maximum), and its Full Width at Half Maximum ([FWHM](#fwhm)).
Other parameters related to the peak shape can be used such as the asymmetry and tailing factors.
To simplify the next steps, the obtained peaks are often reduced to *features*.
These features are uniquely identified and serve as pointers to the peaks, to link additional information in an easier way.

After deconvolution, the last step consists in adding attributes to the obtained features.
These attributes can be of different types, the more numerous they are, the greater the chances of a correct annotation later.
One of these attributes is to attribute an *isotopic pattern* to a feature.
This is usually done by searching for specific mass shifts occurring around the same [RT](#rt), eventually taking peak shapes into account.
The isotopic pattern can be key to later determine the molecular formula ([MF](#mf)) [@doi:10.1021/ed083p1761.2].
With the same reasoning, *adducts* and *neutral losses* can be queried [@doi:10.1021/ac202450g; @doi:10.1038/s41467-021-23953-9]. 
They are additional features generated during the ionization process, that correspond to the same compound.
Some of them are very characteristic and can help with later structural annotation.
Additionally, other features corresponding to peaks with the same peak shape at the same [RT](#rt) can also be linked together [@doi:10.1093/bioinformatics/btz207].
Finally, *fragmentation spectra* can be linked to features.
This is done by searching for fragmentation spectra whose precursor ion corresponds to the [*m/z*](#m/z) and an [RT](#rt) of the corresponding feature (again, with some tolerance).

It is worth noting that considerable effort has been made to make all of these steps available as modules in various software packages [@doi:10.1186/1471-2105-11-395; @doi:10.1038/nmeth.3959; @doi:10.1093/bioinformatics/btr645; @doi:10.1038/s41587-020-0531-2], thus facilitating their use by the end user.
Writing scientific software and making it available to the scientific community comes with a lot of challenges, some described in [@doi:10.1371/journal.pcbi.1002598].
Recently, ways to automate the optimization of all parameters of this complex processing workflow have also been made available [@doi:10.1021/acs.analchem.1c02687].
All these steps, complemented or not with more refined steps such as gap-filling [@doi:10.1021/acs.analchem.0c00899] or mass recalibration [@doi:10.1093/bioinformatics/btq441] lead to a *feature list*.
This feature list can contain thousands of features for a single sample [@doi:10.1007/s11306-009-0168-0; @doi:10.1186/1471-2105-14-15], can be aligned between samples, and is the starting point for further exploration.

##### Data Annotation (From Features to Structures)

The first step to translate those features into something more meaningful is to try to *annotate* them (For the sake of clarity, this section will mainly adress *dereplication* and not *de novo* annotation. See @sec:intro-anno).
As for the chromatogram processing, different tools [@doi:10.1021/acs.analchem.5b04804; @doi:10.1007/978-1-0716-0239-3_11; @doi:10.1038/nmeth.4512; @doi:10.1038/s41596-022-00710-w]allow to annotate features structurally.
Their principles and complexity varies a lot, so the generic steps to achieve a structural annotation will be detailed below.

The first step usually consists in the determination of the [MF](#mf) [@doi:10.1021/acs.jchemed.8b00949].
It can be again performed in various ways, the most common being to generate a list of plausible [MF](#mf)s in a given tolerance around the [*m/z*](#m/z) of the feature.
This step can be refined using isotope patterns [@doi:10.1093/bioinformatics/btn603].

Once the [MF](#mf) is determined (ideally unambiguously), the next step is to search for structures corresponding to this [MF](#mf) in a structural library.
This library can be an *in-house* library, or a publicly available library.
Public structural libraries, their access, size, and quality are an essential condition for good annotation [@doi:10.1021/ac200067s; @doi:10.1016/j.copbio.2018.01.008].
These libraries are usually restricted by their structural [@doi:10/h83p], or taxonomic scope [@doi:10.1093/nar/gkaa868].

Ideally, this step should be complemented by a spectral matching step.
On the side of the feature, this requires to have not only an [MS](#ms)^1^ spectrum associated, but also a fragmentation spectrum.
On the other side, a structural library is not enough anymore, but a spectral library is required instead [@doi:10.1016/j.phytochem.2012.07.007].
As for the structural library, it can be an *in-house* library, a publicly available one [@doi:10.1002/jms.1777; @doi:10.1038/nbt.3597], of more recently, even an *in silico* generated one [@doi:10.1186/s13321-016-0115-9; @doi:10.1021/acs.analchem.1c01465].
Once fragmentation spectra are available on both sides, a score expressing their similarity is calculated.
Except in the case of *variable dereplication* [@doi:10.1038/nchembio.2219], only spectra within a given tolerance around the precursor ion are matched.
The most common metric in [MS](#ms) to evaluate the similarity of two spectra is a dot product [@doi:10/bhw492], also known as *cosine score*.
A more recent variant of the cosine score , the *modified cosine score* allow to align spectra before calculation [@doi:10.1021/jasms.2c00153].
These approaches, even if neglecting some weighing parameters of the original score [@doi:10.1093/bioinformatics/bts083] to be used in a generic way, do not require any training. 
This is not the case of more recent machine learning-based spectral similarity evaluation methods such as Spec2Vec [@doi:10.1371/journal.pcbi.1008724] or MS2DeepScore [@doi:10.1186/s13321-021-00558-4].
Additionally to the spectral matching step, other orthogonal information can help refining the annotation, such as the [RT](#rt).
In the case of an internal library, the [RT](#rt) are easily comparable, but comparison to external libraries can be challenging.
In this area also, machine-learning based tools are being developed [@doi:10.1093/bioinformatics/btaa998; @doi:10.1021/ci9000162].

SIRIUS

Network-based link network to next section

<!-- 
A Modification of the Jaccard–Tanimoto Similarity Index for Diverse Selection of Chemical Compounds Using Binary Strings [@doi:10.1198/004017002317375064]

xMSannotator: An R package for network- based annotation of high-resolution metabolomics data [@doi:10.1021/acs.analchem.6b01214]

iMet: A Network-Based Computational Tool to Assist in the Annotation of Metabolites from Tandem Mass Spectra [@doi:10.1021/acs.analchem.6b04512]

QA/QC [@doi:10.1007/s11306-022-01926-3]
 -->

##### Data Contextualization (From Structures to Biological Context)

`//TODO`{.red}.

Don't forget GNPS metgem

Wikidata and the bibliography of life [@doi:10.7717/peerj.13712]

`//TODO`{.red}.

Link to gene clusters, activities, specialized databases (bitter)

### The *Plant Metabolome*

To refine the first approximation of *plant metabolome* it is first necessary to better define the source it putatively originates from, the plant.

`//TODO`{.red}.

The small molecules can originate from other sources, such as endophytes present inside the plant.

`//TODO`{.red}.

<!-- 

The future of metabolic phytochemistry: larger numbers of metabolites, higher resolution, greater understanding [@doi:10.1016/j.phytochem.2007.07.010]

Computational approaches for systems metabolomics [@doi:10.1016/j.copbio.2016.04.009]

Understanding the holobiont: the interdependence of plants and their microbiome [@doi:10.1016/j.mib.2017.07.001]

Specialized Plant Metabolites: Diversity and Biosynthesis [@doi:10.1002/9783527686063.ch2]

Recent progress in the development of metabolome databases for plant systems biology [@doi:10.3389/fpls.2013.00073]

From waste products to ecochemicals: Fifty years research of plant secondary metabolism [@doi:10.1016/j.phytochem.2007.09.017]

microbiome effect on metabolome [@doi:10.1073/pnas.0812874106]

reading the metabolic fine print [@doi:10.1038/embor.2008.236]

in reality, holobiont [@doi:10.1016/j.mib.2017.07.001]

if needed hologenome [@doi:10.1186/s40168-018-0457-9]

big endophyte book [@doi:10.1007/978-3-319-90484-9_9]

endophytes [@doi:10.3389/fmicb.2016.01538]

number 2 [@doi:10.3389/fbioe.2020.00467] 
-->

<!-- 
NP Rollinger
Virtual screening for the discovery of bioactive natural products [@doi:10.1007/978-3-7643-8117-2_6]
Integrated in Silico Tools for Exploiting the Natural Products’ Bioactivity [@doi:10.1055/s-2006-941506] 
-->